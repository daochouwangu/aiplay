# åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ ç¼–ç å£°æ˜
# -*- coding: utf-8 -*-

import sys
import site
import io
import logging
import cv2
import numpy as np
import pyautogui
import torch
from PIL import Image, ImageDraw, ImageFont
import streamlit as st
from streamlit_drawable_canvas import st_canvas
import time
import traceback
import os
import json
from ultralytics import YOLO
import base64
import platform

# è®¾ç½®æ—¥å¿—çº§åˆ«å’Œç¼–ç 
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', encoding='utf-8')

# æ‰‹åŠ¨æ·»åŠ  ultralytics çš„è·¯å¾„
ultralytics_path = "/Users/liyibing/projects/GitHub/aiplay/.venv/lib/python3.10/site-packages"
if ultralytics_path not in sys.path:
    sys.path.append(ultralytics_path)
    logging.info(f"Added {ultralytics_path} to sys.path")

# å°è¯•å¯¼å…¥ YOLO
try:
    from ultralytics import YOLO
    logging.info("æˆåŠŸå¯¼å…¥ YOLO")
except ImportError as e:
    logging.error(f"å¯¼å…¥ YOLO å¤±è´¥: {e}")

@st.cache_resource
def load_model():
    # æš‚æ—¶æ³¨é‡Šæ‰YOLOæ¨¡å‹åŠ è½½
    model = YOLO('yolo11n.pt')
    return model

def detect_objects(model, image):
    results = model(image)
    return results

def capture_screen_region(left, top, width, height):
    try:
        screenshot = pyautogui.screenshot(region=(left, top, width, height))
        return cv2.cvtColor(np.array(screenshot), cv2.COLOR_RGB2BGR)
    except Exception as e:
        logging.error(f"Error in capture_screen_region: {str(e)}")
        logging.error(traceback.format_exc())
        return None

def save_item_annotation(item_name, x, y, width, height):
    annotation = {
        "item_name": item_name,
        "x": x,
        "y": y,
        "width": width,
        "height": height
    }
    
    annotations = load_annotations()
    annotations.append(annotation)
    
    with open("item_annotations.json", "w", encoding='utf-8') as f:
        json.dump(annotations, f, ensure_ascii=False, indent=4)

def load_annotations():
    try:
        with open("item_annotations.json", "r", encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return []

def execute_instruction(instruction, model, screenshot):
    # ä½¿ç”¨YOLOæ¨¡å‹æ£€æµ‹ç‰©ä½“
    results = detect_objects(model, screenshot)
    
    # è§£ææŒ‡ä»¤å¹¶æ‰§è¡Œ
    instructions = instruction.split('\n')
    execution_log = []

    # æ‰“å° results
    logging.info(f"æ£€æµ‹åˆ°çš„ç‰©ä½“: {results}")
    
    for result in results:
        for box in result.boxes:
            class_id = int(box.cls[0])
            class_name = result.names[class_id]
            confidence = box.conf[0].item()
            x1, y1, x2, y2 = box.xyxy[0].tolist()
            logging.info(f"æ£€æµ‹åˆ° {class_name}ï¼Œç½®ä¿¡åº¦ï¼š{confidence:.2f}ï¼Œä½ç½®ï¼š({x1:.2f}, {y1:.2f}, {x2:.2f}, {y2:.2f})")

    for step in instructions:
        if "ç‚¹å‡»" in step:
            item = step.split("ç‚¹å‡»")[1].strip()
            found = False
            for r in results:
                if len(r.boxes) > 0:  # æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°ä»»ä½•ç‰©ä½“
                    if r.names[int(r.boxes.cls[0])] == item:
                        x, y = r.boxes.xyxy[0][:2].tolist()
                        execution_log.append(f"ç‚¹å‡» {item} åæ ‡ ({x}, {y})")
                        found = True
                        break
            if not found:
                execution_log.append(f"æœªæ‰¾åˆ° {item}")
        elif "æŸ¥æ‰¾" in step:
            item = step.split("æŸ¥æ‰¾")[1].strip()
            found = False
            for r in results:
                if len(r.boxes) > 0:  # æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°ä»»ä½•ç‰©ä½“
                    if r.names[int(r.boxes.cls[0])] == item:
                        x, y, w, h = r.boxes.xyxy[0].tolist()
                        execution_log.append(f"æ‰¾åˆ° {item} åœ¨åæ ‡ ({x}, {y}) å¤§å°ä¸º {w}x{h}")
                        found = True
                        break
            if not found:
                execution_log.append(f"æœªæ‰¾åˆ° {item}")
    
    if not execution_log:
        execution_log.append("æœªæ£€æµ‹åˆ°ä»»ä½•ç‰©ä½“")
    
    return "\n".join(execution_log)

def draw_annotations(image, annotations):
    draw = ImageDraw.Draw(image)
    
    # æ ¹æ®æ“ä½œç³»ç»Ÿé€‰æ‹©åˆé€‚çš„å­—ä½“
    if platform.system() == "Darwin":  # macOS
        font_path = "/System/Library/Fonts/PingFang.ttc"
    elif platform.system() == "Windows":
        font_path = "C:\\Windows\\Fonts\\msyh.ttc"
    else:  # Linux æˆ–å…¶ä»–ç³»ç»Ÿ
        font_path = "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf"
    
    try:
        font = ImageFont.truetype(font_path, 20)
    except OSError:
        st.warning(f"æ— æ³•åŠ è½½å­—ä½“æ–‡ä»¶ {font_path}ï¼Œå°†ä½¿ç”¨é»˜è®¤å­—ä½“ã€‚")
        font = ImageFont.load_default()
    
    for ann in annotations:
        draw.rectangle([ann['x'], ann['y'], ann['x'] + ann['width'], ann['y'] + ann['height']], outline="red", width=2)
        draw.text((ann['x'], ann['y'] - 20), ann['item_name'], fill="red", font=font)
    return image

def main():
    st.set_page_config(page_title="æ™ºèƒ½æ¸¸æˆè¾…åŠ©ç³»ç»Ÿ", page_icon="ğŸ®", layout="wide")
    st.title("æ™ºèƒ½æ¸¸æˆè¾…åŠ©ç³»ç»Ÿ")

    # åˆå§‹åŒ–session_state
    if 'annotations' not in st.session_state:
        st.session_state.annotations = load_annotations()

    try:
        model = load_model()
    except Exception as e:
        st.error(f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™ï¼š{str(e)}")
        logging.error(traceback.format_exc())
        return

    col1, col2 = st.columns(2)
    with col1:
        left = st.number_input("å·¦è¾¹ç•Œ (åƒç´ )", value=50, min_value=0)
        top = st.number_input("ä¸Šè¾¹ç•Œ (åƒç´ )", value=100, min_value=0)
    with col2:
        width = st.number_input("å®½åº¦ (åƒç´ )", value=650, min_value=1)
        height = st.number_input("é«˜åº¦ (åƒç´ )", value=350, min_value=1)

    if st.button("æ•è·å±å¹•"):
        screenshot = capture_screen_region(left, top, width, height)
        if screenshot is not None:
            st.session_state.screenshot = Image.fromarray(cv2.cvtColor(screenshot, cv2.COLOR_BGR2RGB))
            st.session_state.annotations = []  # æ¸…é™¤ä¹‹å‰çš„æ ‡æ³¨
        else:
            st.error("æ— æ³•æ•è·å±å¹•æˆªå›¾")

    if 'screenshot' in st.session_state:
        # æ˜¾ç¤ºå¸¦æœ‰æ ‡æ³¨çš„æˆªå›¾
        annotated_image = draw_annotations(st.session_state.screenshot.copy(), st.session_state.annotations)
        st.image(annotated_image, caption="å½“å‰æ¸¸æˆç”»é¢", use_column_width=True)

        # æ·»åŠ æ¡†é€‰åŠŸèƒ½
        if st_canvas:
            st.write("åœ¨å›¾åƒä¸ŠåŠ¨é¼ æ ‡æ¥æ¡†é€‰ç‰©ä½“")
            canvas_result = st_canvas(
                fill_color="rgba(255, 165, 0, 0.3)",
                stroke_width=2,
                stroke_color="#e00",
                background_image=annotated_image,
                height=annotated_image.height,
                width=annotated_image.width,
                drawing_mode="rect",
                key="canvas",
            )

            # å¤„ç†æ¡†é€‰ç»“æœ
            if canvas_result.json_data is not None:
                objects = canvas_result.json_data["objects"]
                if len(objects) > 0:
                    last_object = objects[-1]
                    item_name = st.text_input("è¾“å…¥ç‰©å“å")
                    if st.button("æ·»åŠ æ ‡æ³¨"):
                        save_item_annotation(
                            item_name,
                            int(last_object["left"]),
                            int(last_object["top"]),
                            int(last_object["width"]),
                            int(last_object["height"])
                        )
                        st.success(f"å·²æ·»åŠ ç‰©å“ '{item_name}' çš„æ ‡æ³¨")
                        st.rerun()
        else:
            st.warning("æ— æ³•åŠ è½½ streamlit_drawable_canvasã€‚æ¡†é€‰åŠŸèƒ½ä¸å¯ç”¨ã€‚")

    # æ˜¾ç¤ºç°æœ‰çš„ç‰©å“æ ‡æ³¨
    if 'annotations' in st.session_state:
        st.write("å·²æ ‡æ³¨çš„ç‰©å“ï¼š", ", ".join([ann["item_name"] for ann in st.session_state.annotations]))
    else:
        st.write("è¿˜æ²¡æœ‰æ ‡æ³¨çš„ç‰©å“ã€‚")

    # æ·»åŠ æŒ‡ä»¤è¾“å…¥å’Œæ‰§è¡ŒåŠŸèƒ½
    st.header("æ‰§è¡ŒæŒ‡ä»¤")
    instruction = st.text_area("è¾“å…¥æŒ‡ä»¤åºåˆ—", value="1. ç‚¹å‡»èƒŒåŒ…\n2. æŸ¥æ‰¾é‡‘å¸\n3. ç‚¹å‡»ä½¿ç”¨æŒ‰é’®")
    
    if st.button("æ‰§è¡ŒæŒ‡ä»¤"):
        with st.spinner("æ­£åœ¨æ‰§è¡ŒæŒ‡ä»¤..."):
            if 'screenshot' not in st.session_state:
                st.error("è¯·å…ˆæ•è·å±å¹•æˆªå›¾")
            else:
                # å°†å›¾åƒè½¬æ¢ä¸º numpy æ•°ç»„å¹¶ç¡®ä¿æ˜¯ BGR æ ¼å¼
                image_np = cv2.cvtColor(np.array(st.session_state.screenshot), cv2.COLOR_RGB2BGR)
                execution_result = execute_instruction(instruction, model, image_np)
                st.write("æ‰§è¡Œç»“æœï¼š", execution_result)

if __name__ == "__main__":
    main()
